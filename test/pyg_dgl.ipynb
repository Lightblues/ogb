{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group_hetero_graph 操作\n",
    "\n",
    "利用 pyg的group_hetero_graph方法, 将异构图转为节点index统一编号的形式! \n",
    "\n",
    "注意到, 该函数的输入仅为基本的torch数据, 因此不影响. 在DGL中只要得到对应类型的输入即可!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tab2graph-gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/mag.zip\n",
      "Extracting /tmp/OGB_MAG/mag/raw/mag.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils.hetero import group_hetero_graph\n",
    "\n",
    "# load sample torch_geometric data\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "# dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "# data = dataset[0]\n",
    "# print(data)\n",
    "\n",
    "# hetrograph OGB_MAG\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "data = OGB_MAG(root='/tmp/OGB_MAG', transform=None)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mpaper\u001b[0m={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389]\n",
       "  },\n",
       "  \u001b[1mauthor\u001b[0m={ num_nodes=1134649 },\n",
       "  \u001b[1minstitution\u001b[0m={ num_nodes=8740 },\n",
       "  \u001b[1mfield_of_study\u001b[0m={ num_nodes=59965 },\n",
       "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
       "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 5416271] },\n",
       "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.hetero_data.HeteroData"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.node_year_dict = None\n",
    "edge_index_dict = data.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = group_hetero_graph(data.edge_index_dict, data.num_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': 736389,\n",
       " 'author': 1134649,\n",
       " 'institution': 8740,\n",
       " 'field_of_study': 59965}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {('author','affiliated_with','institution'): Tensor(2,M)}\n",
    "data.edge_index_dict\n",
    "# {'paper': 736389}\n",
    "data.num_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 736389,  736390,  736391,  ...,  736388,  736388,  736388],\n",
      "        [1871883, 1872034, 1874235,  ..., 1901236, 1902061, 1911712]])\n"
     ]
    }
   ],
   "source": [
    "# pyg/utils/hetro.py\n",
    "import torch\n",
    "\n",
    "\"\"\" 实际调用的转换函数, 可以看到, 和PYG的图结构无关! 因此DGL也可以使用 \"\"\"\n",
    "def pyg_group_hetero_graph(edge_index_dict, num_nodes_dict=None):\n",
    "    # num_nodes_dict = maybe_num_nodes_dict(edge_index_dict, num_nodes_dict)\n",
    "\n",
    "    tmp = list(edge_index_dict.values())[0]\n",
    "\n",
    "    key2int = {}\n",
    "\n",
    "    cumsum, offset = 0, {}  # Helper data.\n",
    "    node_types, local_node_indices = [], []\n",
    "    local2global = {}\n",
    "    for i, (key, N) in enumerate(num_nodes_dict.items()):\n",
    "        key2int[key] = i\n",
    "        node_types.append(tmp.new_full((N, ), i))\n",
    "        local_node_indices.append(torch.arange(N, device=tmp.device))\n",
    "        offset[key] = cumsum\n",
    "        local2global[key] = local_node_indices[-1] + cumsum\n",
    "        local2global[i] = local2global[key]\n",
    "        cumsum += N\n",
    "\n",
    "    node_type = torch.cat(node_types, dim=0)\n",
    "    local_node_idx = torch.cat(local_node_indices, dim=0)\n",
    "\n",
    "    edge_indices, edge_types = [], []\n",
    "    for i, (keys, edge_index) in enumerate(edge_index_dict.items()):\n",
    "        key2int[keys] = i\n",
    "        inc = torch.tensor([offset[keys[0]], offset[keys[-1]]]).view(2, 1)\n",
    "        edge_indices.append(edge_index + inc.to(tmp.device))\n",
    "        edge_types.append(tmp.new_full((edge_index.size(1), ), i))\n",
    "\n",
    "    edge_index = torch.cat(edge_indices, dim=-1)\n",
    "    edge_type = torch.cat(edge_types, dim=0)\n",
    "\n",
    "    return (edge_index, edge_type, node_type, local_node_idx, local2global,\n",
    "            key2int)\n",
    "\n",
    "edge_index, edge_type, node_type, local_node_idx, local2global, key2int = pyg_group_hetero_graph(data.edge_index_dict, data.num_nodes_dict)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': tensor([[-0.0954,  0.0408, -0.2109,  ...,  0.0616, -0.0277, -0.1338],\n",
       "         [-0.1510, -0.1073, -0.2220,  ...,  0.3458, -0.0277, -0.2185],\n",
       "         [-0.1148, -0.1760, -0.2606,  ...,  0.1731, -0.1564, -0.2780],\n",
       "         ...,\n",
       "         [ 0.0228, -0.0865,  0.0981,  ..., -0.0547, -0.2077, -0.2305],\n",
       "         [-0.2891, -0.2029, -0.1525,  ...,  0.1042,  0.2041, -0.3528],\n",
       "         [-0.0890, -0.0348, -0.2642,  ...,  0.2601, -0.0875, -0.5171]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([736389, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict['paper'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': tensor([246, 131, 189,  ..., 266, 289,   1])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在DGL图上实现 pyg.HeteroData 接口\n",
    "\n",
    "总结 sampler.py 涉及到的data接口 (HeteroData)\n",
    "\n",
    "```python\n",
    "data.edge_index_dict: {('author','affiliated_with','institution'): Tensor(2,M)}\n",
    "data.num_nodes_dict: {'paper': 736389}\n",
    "# N=736389 paper数量\n",
    "data.x_dict: 只包含 {'paper': Tensor(N,features)}\n",
    "data.y_dict: 只包含 {'paper': Tensor(N)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data.hetero_data import HeteroData\n",
    "\n",
    "data = HeteroData()\n",
    "data.y_dict\n",
    "data.x_dict\n",
    "data.num_nodes_dict\n",
    "data.edge_index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'affiliated_with': 5, 'author': 5, 'cites': 100, 'has_topic': 100, 'institution': 3, 'paper': 100, 'paper2': 100, 'writes': 100},\n",
       "       num_edges={('affiliated_with', 'affiliated_with-author-author', 'author'): 5, ('affiliated_with', 'affiliated_with-institution-institution', 'institution'): 5, ('author', 'reverse-affiliated_with-author-author', 'affiliated_with'): 5, ('author', 'reverse-writes-author-author', 'writes'): 100, ('cites', 'cites-paper_cite-paper', 'paper'): 100, ('cites', 'cites-paper_cited-paper2', 'paper2'): 100, ('has_topic', 'has_topic-paper-paper', 'paper'): 100, ('institution', 'reverse-affiliated_with-institution-institution', 'affiliated_with'): 5, ('paper', 'reverse-cites-paper_cite-paper', 'cites'): 100, ('paper', 'reverse-has_topic-paper-paper', 'has_topic'): 100, ('paper', 'reverse-writes-paper-paper', 'writes'): 100, ('paper2', 'reverse-cites-paper_cited-paper2', 'cites'): 100, ('writes', 'writes-author-author', 'author'): 100, ('writes', 'writes-paper-paper', 'paper'): 100},\n",
       "       metagraph=[('affiliated_with', 'author', 'affiliated_with-author-author'), ('affiliated_with', 'institution', 'affiliated_with-institution-institution'), ('author', 'affiliated_with', 'reverse-affiliated_with-author-author'), ('author', 'writes', 'reverse-writes-author-author'), ('institution', 'affiliated_with', 'reverse-affiliated_with-institution-institution'), ('writes', 'author', 'writes-author-author'), ('writes', 'paper', 'writes-paper-paper'), ('cites', 'paper', 'cites-paper_cite-paper'), ('cites', 'paper2', 'cites-paper_cited-paper2'), ('paper', 'cites', 'reverse-cites-paper_cite-paper'), ('paper', 'has_topic', 'reverse-has_topic-paper-paper'), ('paper', 'writes', 'reverse-writes-paper-paper'), ('paper2', 'cites', 'reverse-cites-paper_cited-paper2'), ('has_topic', 'paper', 'has_topic-paper-paper')])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.data.utils import load_graphs, save_graphs, Subset\n",
    "pre_processed_file_path = \"/home/ec2-user/workspace/tab2graph/datasets/tiny/dgl_data_processed\"\n",
    "# pre_processed_file_path = \"/home/ec2-user/workspace/ogb/dataset/tiny/dgl_data_processed\"\n",
    "graph, label_dict = load_graphs(pre_processed_file_path)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dgl.heterograph.DGLGraph"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl import DGLGraph\n",
    "\n",
    "g:DGLGraph = graph[0]\n",
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'affiliated_with': 5, 'author': 5, 'cites': 100, 'has_topic': 100, 'institution': 3, 'paper': 100, 'paper2': 100, 'writes': 100},\n",
      "      num_edges={('affiliated_with', 'affiliated_with-author-author', 'author'): 5, ('affiliated_with', 'affiliated_with-institution-institution', 'institution'): 5, ('author', 'reverse-affiliated_with-author-author', 'affiliated_with'): 5, ('author', 'reverse-writes-author-author', 'writes'): 100, ('cites', 'cites-paper_cite-paper', 'paper'): 100, ('cites', 'cites-paper_cited-paper2', 'paper2'): 100, ('has_topic', 'has_topic-paper-paper', 'paper'): 100, ('institution', 'reverse-affiliated_with-institution-institution', 'affiliated_with'): 5, ('paper', 'reverse-cites-paper_cite-paper', 'cites'): 100, ('paper', 'reverse-has_topic-paper-paper', 'has_topic'): 100, ('paper', 'reverse-writes-paper-paper', 'writes'): 100, ('paper2', 'reverse-cites-paper_cited-paper2', 'cites'): 100, ('writes', 'writes-author-author', 'author'): 100, ('writes', 'writes-paper-paper', 'paper'): 100},\n",
      "      metagraph=[('affiliated_with', 'author', 'affiliated_with-author-author'), ('affiliated_with', 'institution', 'affiliated_with-institution-institution'), ('author', 'affiliated_with', 'reverse-affiliated_with-author-author'), ('author', 'writes', 'reverse-writes-author-author'), ('institution', 'affiliated_with', 'reverse-affiliated_with-institution-institution'), ('writes', 'author', 'writes-author-author'), ('writes', 'paper', 'writes-paper-paper'), ('cites', 'paper', 'cites-paper_cite-paper'), ('cites', 'paper2', 'cites-paper_cited-paper2'), ('paper', 'cites', 'reverse-cites-paper_cite-paper'), ('paper', 'has_topic', 'reverse-has_topic-paper-paper'), ('paper', 'writes', 'reverse-writes-paper-paper'), ('paper2', 'cites', 'reverse-cites-paper_cited-paper2'), ('has_topic', 'paper', 'has_topic-paper-paper')])\n"
     ]
    }
   ],
   "source": [
    "def add_properties_to_dgl(g:DGLGraph):\n",
    "    \"\"\" 添加 edge_index_dict, num_nodes_dict, x_dict, y_dict 属性\n",
    "    \"\"\"\n",
    "    graph = g.clone()\n",
    "\n",
    "    # 在 convert_dglData.py 中, 预先将数据放进去\n",
    "    graph.x_dict = graph.ndata['feat']\n",
    "    graph.y_dict = graph.ndata['label']\n",
    "    \n",
    "    edge_index_dict = {}\n",
    "    for edge_type in graph.canonical_etypes:\n",
    "        src, dst = graph.all_edges(form='uv', etype=edge_type, order='srcdst')\n",
    "        edge_index_dict[edge_type] = torch.stack([src, dst], dim=0)\n",
    "    graph.edge_index_dict = edge_index_dict\n",
    "    \n",
    "    num_nodes_dict = {}\n",
    "    for ntype in graph.ntypes:\n",
    "        num_nodes_dict[ntype] = graph.number_of_nodes(ntype)\n",
    "    graph.num_nodes_dict = num_nodes_dict\n",
    "    \n",
    "    return graph\n",
    "\n",
    "g_added = add_properties_to_dgl(g)\n",
    "print(g_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('affiliated_with', 'affiliated_with-author-author', 'author')\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([0, 1, 2, 3, 4]))\n",
      "('affiliated_with', 'affiliated_with-institution-institution', 'institution')\n",
      "(tensor([0, 2, 1, 3, 4]), tensor([0, 0, 1, 1, 2]))\n",
      "('author', 'reverse-affiliated_with-author-author', 'affiliated_with')\n",
      "(tensor([0, 1, 2, 3, 4]), tensor([0, 1, 2, 3, 4]))\n",
      "('author', 'reverse-writes-author-author', 'writes')\n",
      "(tensor([3, 1, 4, 4, 3, 4, 4, 1, 0, 0, 1, 0, 3, 0, 4, 1, 2, 4, 4, 3, 2, 3, 1, 2,\n",
      "        1, 0, 4, 0, 1, 3, 4, 4, 2, 0, 1, 1, 1, 1, 3, 1, 3, 3, 2, 2, 0, 1, 3, 2,\n",
      "        1, 2, 2, 0, 3, 3, 2, 1, 3, 0, 3, 0, 1, 2, 1, 1, 0, 1, 2, 3, 0, 0, 1, 1,\n",
      "        1, 4, 2, 1, 4, 0, 2, 4, 0, 3, 3, 2, 4, 4, 0, 3, 3, 1, 4, 2, 3, 2, 2, 1,\n",
      "        3, 2, 3, 1]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('cites', 'cites-paper_cite-paper', 'paper')\n",
      "(tensor([59, 60, 84, 96, 42, 81,  4, 74,  8, 92,  7, 27, 99, 18, 12,  9, 68, 98,\n",
      "        78, 93,  0, 26, 15, 83, 62, 32, 37, 65, 97, 45, 87,  3, 16, 50, 95,  2,\n",
      "         1, 17, 67, 72, 28, 33, 70, 22, 76, 39, 52, 64, 19, 30, 11, 14, 77, 46,\n",
      "        56, 89, 73, 47, 55, 94, 13, 58, 61, 85, 49, 86, 10, 38, 63, 21, 71, 90,\n",
      "        35, 91, 29, 75, 25, 48, 82, 36, 40,  5,  6, 54, 20, 24, 41, 88, 23, 66,\n",
      "        79, 43, 31, 34, 44, 69, 80, 51, 53, 57]), tensor([ 1,  1,  2,  2,  5,  5,  7,  8, 10, 14, 15, 15, 15, 16, 18, 19, 19, 19,\n",
      "        20, 21, 22, 23, 24, 24, 25, 27, 27, 27, 27, 28, 28, 30, 32, 33, 33, 35,\n",
      "        37, 39, 43, 43, 44, 45, 45, 46, 46, 48, 48, 50, 52, 55, 56, 60, 64, 65,\n",
      "        65, 65, 67, 68, 69, 69, 71, 71, 71, 71, 72, 75, 77, 77, 77, 80, 80, 80,\n",
      "        81, 82, 83, 83, 84, 85, 85, 87, 87, 88, 88, 89, 90, 94, 94, 95, 96, 96,\n",
      "        96, 97, 98, 98, 98, 98, 98, 99, 99, 99]))\n",
      "('cites', 'cites-paper_cited-paper2', 'paper2')\n",
      "(tensor([98, 67, 11, 22, 40, 71, 55, 21, 46, 32, 51, 86, 57, 26, 15, 28, 73, 99,\n",
      "        19, 31, 69, 38, 91,  1, 36, 63, 49, 80, 59, 76, 85, 89, 62,  2, 97, 25,\n",
      "        47, 92, 16, 95,  4, 52, 83,  5, 43, 94, 12, 64, 58, 34, 45, 66, 42,  7,\n",
      "        53, 75, 90, 10, 27, 48, 50, 30, 13, 24, 33, 87, 18,  8, 68, 54, 29, 74,\n",
      "        56, 37,  0, 78, 96, 79, 82, 39, 23, 61,  6, 35, 77, 14, 41, 70, 44, 60,\n",
      "        88,  9, 72, 65, 81, 17,  3, 20, 93, 84]), tensor([ 2,  4,  5,  5,  5,  5,  7,  9, 10, 14, 14, 14, 15, 16, 17, 17, 17, 17,\n",
      "        22, 25, 26, 28, 28, 29, 29, 29, 30, 31, 32, 32, 32, 32, 34, 35, 37, 42,\n",
      "        43, 43, 45, 46, 48, 48, 48, 49, 50, 50, 51, 51, 52, 53, 53, 53, 55, 56,\n",
      "        56, 56, 56, 58, 59, 59, 59, 60, 61, 61, 61, 61, 62, 63, 64, 65, 68, 68,\n",
      "        69, 70, 71, 72, 72, 73, 73, 74, 76, 78, 80, 81, 81, 83, 84, 84, 86, 87,\n",
      "        87, 88, 88, 89, 94, 96, 97, 97, 97, 99]))\n",
      "('has_topic', 'has_topic-paper-paper', 'paper')\n",
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('institution', 'reverse-affiliated_with-institution-institution', 'affiliated_with')\n",
      "(tensor([0, 1, 0, 1, 2]), tensor([0, 1, 2, 3, 4]))\n",
      "('paper', 'reverse-cites-paper_cite-paper', 'cites')\n",
      "(tensor([22, 37, 35, 30,  7, 88, 88, 15, 10, 19, 77, 56, 18, 71, 60, 24, 32, 39,\n",
      "        16, 52, 90, 80, 46, 96, 94, 84, 23, 15, 44, 83, 55, 98, 27, 45, 98, 81,\n",
      "        87, 27, 77, 48, 87, 94,  5, 97, 98, 28, 65, 68, 85, 72, 33, 99, 48, 99,\n",
      "        89, 69, 65, 99, 71,  1,  1, 71, 25, 77, 50, 27, 96, 43, 19, 98, 45, 80,\n",
      "        43, 67,  8, 83, 46, 64, 20, 96, 98,  5, 85, 24,  2, 71, 75, 28, 95, 65,\n",
      "        80, 82, 14, 21, 69, 33,  2, 27, 19, 15]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('paper', 'reverse-has_topic-paper-paper', 'has_topic')\n",
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('paper', 'reverse-writes-paper-paper', 'writes')\n",
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('paper2', 'reverse-cites-paper_cited-paper2', 'cites')\n",
      "(tensor([71, 29, 35, 97, 48, 49, 80, 56, 63, 88, 58,  5, 51, 61, 83, 17, 45, 96,\n",
      "        62, 22, 97,  9,  5, 76, 61, 42, 16, 59, 17, 68, 60, 25, 14, 61, 53, 81,\n",
      "        29, 70, 28, 74,  5, 84, 55, 50, 86, 53, 10, 43, 59, 30, 59, 14, 48, 56,\n",
      "        65,  7, 69, 15, 52, 32, 87, 78, 34, 29, 51, 89, 53,  4, 64, 26, 84,  5,\n",
      "        88, 17, 68, 56, 32, 81, 72, 73, 31, 94, 73, 48, 99, 32, 14, 61, 87, 32,\n",
      "        56, 28, 43, 97, 50, 46, 72, 37,  2, 17]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "('writes', 'writes-author-author', 'author')\n",
      "(tensor([ 8,  9, 11, 13, 25, 27, 33, 44, 51, 57, 59, 64, 68, 69, 77, 80, 86,  1,\n",
      "         7, 10, 15, 22, 24, 28, 34, 35, 36, 37, 39, 45, 48, 55, 60, 62, 63, 65,\n",
      "        70, 71, 72, 75, 89, 95, 99, 16, 20, 23, 32, 42, 43, 47, 49, 50, 54, 61,\n",
      "        66, 74, 78, 83, 91, 93, 94, 97,  0,  4, 12, 19, 21, 29, 38, 40, 41, 46,\n",
      "        52, 53, 56, 58, 67, 81, 82, 87, 88, 92, 96, 98,  2,  3,  5,  6, 14, 17,\n",
      "        18, 26, 30, 31, 73, 76, 79, 84, 85, 90]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4]))\n",
      "('writes', 'writes-paper-paper', 'paper')\n",
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n"
     ]
    }
   ],
   "source": [
    "# # https://docs.dgl.ai/en/latest/api/python/dgl.DGLGraph.html\n",
    "# # 相较于 etyps, g.canonical_etypes 是三元组形式的\n",
    "# g.etypes\n",
    "# g.canonical_etypes\n",
    "# etype = 'affiliated_with-author-author'\n",
    "# etype = ('affiliated_with', 'affiliated_with-author-author', 'author')\n",
    "\n",
    "# # g.edges(etype=etype, order='srcdst') #, form='all')\n",
    "# for etype in g.canonical_etypes:\n",
    "#     print(etype)\n",
    "#     print(g.edges(etype=etype, order='srcdst'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g.ntypes\n",
    "# g.num_nodes(ntype='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0409,  0.1130,  0.5719],\n",
      "        [-0.6358, -0.0969, -0.0738]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试 torch的 Linear层\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# 1. 定义一个线性层\n",
    "linear = nn.Linear(5, 3)\n",
    "# 2. 定义一个输入\n",
    "x = torch.randn(2, 5)\n",
    "# 3. 计算输出\n",
    "y = linear(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空间占用分析\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_size_tensor(t:torch.Tensor):\n",
    "    return t.element_size() * t.numel()\n",
    "\n",
    "def get_size(x):\n",
    "    if type(x) == torch.Tensor:\n",
    "        return get_size_tensor(x)\n",
    "    elif type(x) == list:\n",
    "        return sum([get_size_tensor(t) for t in x])\n",
    "    elif type(x) == dict:\n",
    "        return sum([get_size_tensor(t) for t in x.values()])\n",
    "\n",
    "for name in 'x_dict edge_type node_type local_node_idx y_global'.split():\n",
    "    x = eval(name)\n",
    "    size_GB = get_size(x) / 1024**3\n",
    "    print(f'{name}: {size_GB:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab2graph-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
